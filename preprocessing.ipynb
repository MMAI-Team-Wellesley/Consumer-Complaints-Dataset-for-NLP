{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import re\n", "import string\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from nltk.stem import WordNetLemmatizer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "This function cleans the text in the \"narrative\" column of the dataframe. <br>\n", "It removes URLs, HTML tags, punctuation, numbers, stopwords, and lemmatizes the text.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "For the data cleaning team, only edit this file. Feel free to test the functions with the dataset<br>\n", "in this file, but do not change the original dataset.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_text(text):\n", "    # Remove URLs from text\n", "    text = re.sub(r'http\\S+', '', text)\n", "    # Remove HTML tags from text\n", "    text = re.sub(r'<.*?>', '', text)\n", "    # Convert text to lowercase\n", "    text = text.lower()\n", "    # Remove punctuation from text\n", "    text = text.translate(str.maketrans('', '', string.punctuation))\n", "    # Remove numbers from text\n", "    text = re.sub(r'\\d+', '', text)\n", "    # Remove stopwords from text\n", "    nltk.download('stopwords')\n", "    stop_words = set(stopwords.words('english'))\n", "    text_tokens = nltk.word_tokenize(text)\n", "    text = [word for word in text_tokens if not word in stop_words]\n", "    text = ' '.join(text)\n", "    # Lemmatize text\n", "    nltk.download('wordnet')\n", "    lemmatizer = WordNetLemmatizer()\n", "    text_tokens = nltk.word_tokenize(text)\n", "    text = [lemmatizer.lemmatize(word) for word in text_tokens]\n", "    text = ' '.join(text)\n", "    return text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_data(df):\n", "    # Remove the \"Unnamed: 0\" column\n", "    df = df.drop(columns=['Unnamed: 0'])\n", "    # Clean the \"product\" column\n", "    df['product'] = df['product'].apply(lambda x: x.lower())\n", "    # Clean the \"narrative\" column\n", "    df['narrative'] = df['narrative'].apply(lambda x: clean_text(x))\n", "    return df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import the dataset \"complaints_processed.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('complaints_processed.csv')\n", "test_df_clean = preprocess_data(df)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}